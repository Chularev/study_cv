{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Оглавление<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data-loader\" data-toc-modified-id=\"Data-loader-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data loader</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data_preparer import get_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'validation' to '/mnt/heap/validation' if necessary\n",
      "Found annotations at '/mnt/heap/raw/instances_val2017.json'\n",
      "Images already downloaded\n",
      "Existing download of split 'validation' is sufficient\n",
      "Loading 'coco-2017' split 'validation'\n",
      " 100% |███████████████| 5000/5000 [22.7s elapsed, 0s remaining, 234.5 samples/s]      \n",
      "Dataset 'coco-2017-validation' created\n",
      "person_view len = 1005\n",
      "train dataset = 753\n",
      "test dataset = 252\n"
     ]
    }
   ],
   "source": [
    "torch_dataset, torch_dataset_test = get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from pytorch_helper import PyTorchHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extended_model import ExtendedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_helper import PyTorchHelper\n",
    "\n",
    "def find_hyperparameters(config, data_train, data_test):\n",
    "    # define training and validation data loaders\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        data_train, batch_size=64, shuffle=True)\n",
    "    \n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "        data_test, batch_size=64, shuffle=False)\n",
    "\n",
    "    learning_rates = [1e-1]\n",
    "    anneal_coeff = 0.5\n",
    "    anneal_epochs = [5]\n",
    "    regs = config['regs']\n",
    "    optimizers = config['optimizers']\n",
    "\n",
    "    batch_size = 64\n",
    "    epoch_num = 5\n",
    "\n",
    "    run_record = {} \n",
    "    \n",
    "    helper = PyTorchHelper(8,  None)\n",
    "\n",
    "    lenet_model = None\n",
    "    val_loss = 8\n",
    "    loss_history = None\n",
    "    for lr, reg, anneal_epoch, optimizer in product(learning_rates, regs, anneal_epochs, optimizers):\n",
    "        \n",
    "        lenet_model = ExtendedModel(config['model'](), config['need_train'], config['model_name'])\n",
    "        if not lenet_model.need_train:\n",
    "            if lenet_model.load_model():\n",
    "                return lenet_model\n",
    "        \n",
    "        optimizer = optimizer(lenet_model.torch_model.parameters(), lr=lr, weight_decay=reg)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=anneal_epoch, gamma=anneal_coeff)\n",
    "\n",
    "        model, train_loss_history, val_loss_history, train_metric_history, val_metric_history = helper.train_model(lenet_model.torch_model, data_loader, data_loader_test, optimizer, epoch_num, scheduler)\n",
    "        lenet_model.add_history(train_loss_history, val_loss_history, train_metric_history, val_metric_history)\n",
    "\n",
    "    return lenet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.model = resnet18(pretrained=True)\n",
    "        self.model.fc = nn.Linear(in_features=512, out_features=5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'need_train': True,\n",
    "    'regs': [0.001],\n",
    "    'optimizers': [optim.Adam],\n",
    "    'model': Net,\n",
    "    'model_name': 'best_lenet'    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resource_monitor import ResourceMonitor\n",
    "resourceMonitor = ResourceMonitor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory_allocated: 0.0\n",
      "max_memory_allocated: 0.0\n",
      "memory_reserved: 0.0\n",
      "max_memory_reserved: 0.0\n"
     ]
    }
   ],
   "source": [
    "resourceMonitor.print_statistics('MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-ae5601bd6a65>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [15]\u001b[0;36m\u001b[0m\n\u001b[0;31m    ==========================================\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "=========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Ray automatically.For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-07 17:34:46,175\tINFO services.py:1338 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "2022-02-07 17:34:49,117\tWARNING function_runner.py:561 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-07 17:34:49 (running for 00:00:00.15)<br>Memory usage on this node: 5.4/7.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/2.0 GiB heap, 0.0/1.0 GiB objects<br>Result logdir: /mnt/heap/My folder/checpoint/experiment_name<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>find_hyperparameters_936ad_00000</td><td>PENDING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-07 17:34:54 (running for 00:00:05.21)<br>Memory usage on this node: 6.4/7.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/2.0 GiB heap, 0.0/1.0 GiB objects<br>Result logdir: /mnt/heap/My folder/checpoint/experiment_name<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc               </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>find_hyperparameters_936ad_00000</td><td>RUNNING </td><td>192.168.0.105:9985</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-07 17:34:59 (running for 00:00:10.24)<br>Memory usage on this node: 7.5/7.7 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/2.0 GiB heap, 0.0/1.0 GiB objects<br>Result logdir: /mnt/heap/My folder/checpoint/experiment_name<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc               </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>find_hyperparameters_936ad_00000</td><td>RUNNING </td><td>192.168.0.105:9985</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m ==============================\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m Start train:\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m memory_allocated: 42.69677734375\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m max_memory_allocated: 42.69677734375\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m memory_reserved: 64.0\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m max_memory_reserved: 64.0\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m ==============================\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m Epoch 0/4. Phase train\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m ----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-07 17:35:04 (running for 00:00:15.27)<br>Memory usage on this node: 7.5/7.7 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/2.0 GiB heap, 0.0/1.0 GiB objects<br>Result logdir: /mnt/heap/My folder/checpoint/experiment_name<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc               </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>find_hyperparameters_936ad_00000</td><td>RUNNING </td><td>192.168.0.105:9985</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m Step 0/12 Loss 0.8755924701690674\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-07 17:35:09 (running for 00:00:20.29)<br>Memory usage on this node: 7.5/7.7 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/2.0 GiB heap, 0.0/1.0 GiB objects<br>Result logdir: /mnt/heap/My folder/checpoint/experiment_name<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc               </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>find_hyperparameters_936ad_00000</td><td>RUNNING </td><td>192.168.0.105:9985</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m Step 1/12 Loss 31.85561752319336\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-07 17:35:14 (running for 00:00:25.30)<br>Memory usage on this node: 7.5/7.7 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/2.0 GiB heap, 0.0/1.0 GiB objects<br>Result logdir: /mnt/heap/My folder/checpoint/experiment_name<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc               </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>find_hyperparameters_936ad_00000</td><td>RUNNING </td><td>192.168.0.105:9985</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m Step 2/12 Loss 19.075115203857422\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-07 17:35:19 (running for 00:00:30.30)<br>Memory usage on this node: 7.5/7.7 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/2.0 GiB heap, 0.0/1.0 GiB objects<br>Result logdir: /mnt/heap/My folder/checpoint/experiment_name<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc               </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>find_hyperparameters_936ad_00000</td><td>RUNNING </td><td>192.168.0.105:9985</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m Step 3/12 Loss 8.290144920349121\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-07 17:35:24 (running for 00:00:35.31)<br>Memory usage on this node: 7.5/7.7 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/2.0 GiB heap, 0.0/1.0 GiB objects<br>Result logdir: /mnt/heap/My folder/checpoint/experiment_name<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc               </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>find_hyperparameters_936ad_00000</td><td>RUNNING </td><td>192.168.0.105:9985</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m Step 4/12 Loss 3.8655877113342285\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-07 17:35:29 (running for 00:00:40.31)<br>Memory usage on this node: 7.5/7.7 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/2.0 GiB heap, 0.0/1.0 GiB objects<br>Result logdir: /mnt/heap/My folder/checpoint/experiment_name<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc               </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>find_hyperparameters_936ad_00000</td><td>RUNNING </td><td>192.168.0.105:9985</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m Step 5/12 Loss 3.846971035003662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-07 17:35:32,646\tWARNING tune.py:582 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-07 17:35:32 (running for 00:00:43.32)<br>Memory usage on this node: 7.5/7.7 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/2.0 GiB heap, 0.0/1.0 GiB objects<br>Result logdir: /mnt/heap/My folder/checpoint/experiment_name<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc               </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>find_hyperparameters_936ad_00000</td><td>RUNNING </td><td>192.168.0.105:9985</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m 2022-02-07 17:35:32,734\tERROR worker.py:431 -- SystemExit was raised from the worker\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m   File \"python/ray/_raylet.pyx\", line 759, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m   File \"python/ray/_raylet.pyx\", line 580, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m   File \"python/ray/_raylet.pyx\", line 618, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m   File \"python/ray/_raylet.pyx\", line 625, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m   File \"python/ray/_raylet.pyx\", line 629, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m   File \"python/ray/_raylet.pyx\", line 578, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m   File \"/home/alex/.local/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 609, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m   File \"/home/alex/.local/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m   File \"/home/alex/.local/lib/python3.8/site-packages/ray/tune/trainable.py\", line 255, in train_buffered\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m     result = self.train()\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m   File \"/home/alex/.local/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m   File \"/home/alex/.local/lib/python3.8/site-packages/ray/tune/trainable.py\", line 314, in train\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m     result = self.step()\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m   File \"/home/alex/.local/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m   File \"/home/alex/.local/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 363, in step\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m     result = self._results_queue.get(\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m   File \"/usr/lib/python3.8/queue.py\", line 179, in get\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m     self.not_empty.wait(remaining)\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 306, in wait\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m     gotit = waiter.acquire(True, timeout)\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m   File \"/home/alex/.local/lib/python3.8/site-packages/ray/worker.py\", line 428, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=9985)\u001b[0m SystemExit: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m analysis \u001b[38;5;241m=\u001b[39m \u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfind_hyperparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mdata_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dataset_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43msync_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSyncConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m         \u001b[49m\u001b[43msyncer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Disable syncing\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexperiment_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/mnt/heap/My folder/checpoint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresources_per_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/ray/tune/tune.py:611\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, max_concurrent_trials, queue_trials, loggers, _remote)\u001b[0m\n\u001b[1;32m    608\u001b[0m     _report_progress(runner, progress_reporter, done\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    610\u001b[0m wait_for_sync()\n\u001b[0;32m--> 611\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcleanup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m incomplete_trials \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mget_trials():\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/ray/tune/trial_runner.py:1386\u001b[0m, in \u001b[0;36mTrialRunner.cleanup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcleanup\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1385\u001b[0m     \u001b[38;5;124;03m\"\"\"Cleanup trials and callbacks.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1386\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcleanup_trials\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_experiment_callbacks()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/ray/tune/trial_runner.py:1382\u001b[0m, in \u001b[0;36mTrialRunner.cleanup_trials\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcleanup_trials\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1382\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_and_catch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrial_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcleanup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/ray/tune/trial_runner.py:446\u001b[0m, in \u001b[0;36mTrialRunner._run_and_catch\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;124;03m\"\"\"Run the corresponding `func`.\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \n\u001b[1;32m    429\u001b[0m \u001b[38;5;124;03mFirst try to run the function with trials as argument. If the function\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03mlead to weird behaviors.\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 446\u001b[0m     \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_trials\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlist\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_trials\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py:1010\u001b[0m, in \u001b[0;36mRayTrialExecutor.cleanup\u001b[0;34m(self, trials)\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pg_manager\u001b[38;5;241m.\u001b[39mreconcile_placement_groups(trials)\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pg_manager\u001b[38;5;241m.\u001b[39mcleanup(force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 1010\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pg_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcleanup_existing_pg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/ray/tune/utils/placement_groups.py:390\u001b[0m, in \u001b[0;36mPlacementGroupManager.cleanup_existing_pg\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m    387\u001b[0m         pgf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unstaged_pg_pgf\u001b[38;5;241m.\u001b[39mpop(pg)\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unstaged_pgf_pg[pgf]\u001b[38;5;241m.\u001b[39mdiscard(pg)\n\u001b[0;32m--> 390\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "analysis = tune.run(\n",
    "    tune.with_parameters(find_hyperparameters,  data_train=torch_dataset, data_test=torch_dataset_test),\n",
    "    sync_config=tune.SyncConfig(\n",
    "         syncer=None  # Disable syncing\n",
    "    ),\n",
    "    name=\"experiment_name\",\n",
    "    local_dir=\"/mnt/heap/My folder/checpoint\",\n",
    "    num_samples=1,\n",
    "    config=config,\n",
    "    resources_per_trial={\"cpu\": 8, \"gpu\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_model = find_hyperparameters(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.visualize_loss_history(extended_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.visualize_metric_history(extended_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resourceMonitor.print_statistics('MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "==============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_model.save_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_model.deployment_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "==============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(index):\n",
    "    img, target = torch_dataset[index]\n",
    "    pred = extended_model.torch_model(img.unsqueeze(0))[0]\n",
    "    \n",
    "    original_img = Image.open(target['img_path']).convert(\"RGB\")\n",
    "    viewer.print_prediction(original_img, target, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10, 170):\n",
    "    predict(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "==============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "==============================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "def convert_torch_predictions(preds, det_id, s_id, w, h, classes):\n",
    "    # Convert the outputs of the torch model into a FiftyOne Detections object\n",
    "    dets = []\n",
    "    #if preds[0] < 0.5:\n",
    "     #   detections = fo.Detections(detections=dets)\n",
    "      #  return detections, det_id\n",
    "    \n",
    "    # Parse prediction into FiftyOne Detection object\n",
    "    x0,y0,x1,y1 = preds[1:]\n",
    "    coco_obj = fouc.COCOObject(det_id, s_id, int(1), [x0, y0, x1-x0, y1-y0])\n",
    "    det = coco_obj.to_detection((w,h), classes)\n",
    "    dets.append(det)\n",
    "    det_id += 1\n",
    "        \n",
    "    detections = fo.Detections(detections=dets)\n",
    "        \n",
    "    return detections, det_id\n",
    "\n",
    "def add_detections(model, torch_dataset, view, field_name=\"predictions\"):\n",
    "    # Run inference on a dataset and add results to FiftyOne\n",
    "    torch.set_num_threads(1)\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    print(\"Using device %s\" % device)\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    image_paths = torch_dataset.img_paths\n",
    "    classes = torch_dataset.classes\n",
    "    det_id = 0\n",
    "    \n",
    "    with fo.ProgressBar() as pb:\n",
    "        for img, targets in pb(torch_dataset):\n",
    "            sample = view[targets[\"img_path\"]]\n",
    "            s_id = sample.id\n",
    "            w = sample.metadata[\"width\"]\n",
    "            h = sample.metadata[\"height\"]\n",
    "            \n",
    "            # Inference\n",
    "            preds = model(img.unsqueeze(0).to(device))[0]\n",
    "            \n",
    "            detections, det_id = convert_torch_predictions(\n",
    "                preds, \n",
    "                det_id, \n",
    "                s_id, \n",
    "                w, \n",
    "                h, \n",
    "                classes,\n",
    "            )\n",
    "            \n",
    "            sample[\"predictions\"] = detections\n",
    "            sample.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_detections(model, torch_dataset_test, fo_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = fo.launch_app(fo_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Оглавление",
   "title_sidebar": "Оглавление",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
