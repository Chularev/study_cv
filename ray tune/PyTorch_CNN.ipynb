{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RKgBwXr-YM8"
   },
   "source": [
    "# Задание 3.2 - сверточные нейронные сети (CNNs) в PyTorch\n",
    "\n",
    "Это упражнение мы буде выполнять в Google Colab - https://colab.research.google.com/  \n",
    "Google Colab позволяет запускать код в notebook в облаке Google, где можно воспользоваться бесплатным GPU!  \n",
    "\n",
    "Авторы курса благодарят компанию Google и надеятся, что праздник не закончится.\n",
    "\n",
    "Туториал по настройке Google Colab:  \n",
    "https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d  \n",
    "(Keras инсталлировать не нужно, наш notebook сам установит PyTorch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FcXBeP1O7cnY",
    "outputId": "fd0c07fe-1ea3-42ed-80b5-80e4f7b9d161"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.10.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.11.1)\n",
      "Requirement already satisfied: typing-extensions in /home/alex/.local/lib/python3.8/site-packages (from torch) (4.0.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.20.3)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /home/alex/.local/lib/python3.8/site-packages (from torchvision) (8.4.0)\n",
      "--2022-01-31 22:05:26--  http://ufldl.stanford.edu/housenumbers/train_32x32.mat\n",
      "Распознаётся ufldl.stanford.edu (ufldl.stanford.edu)... 171.64.68.10\n",
      "Подключение к ufldl.stanford.edu (ufldl.stanford.edu)|171.64.68.10|:80... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа... 416 Requested Range Not Satisfiable\n",
      "\n",
      "    Файл уже получен полностью; нет действий.\n",
      "\n",
      "--2022-01-31 22:05:27--  http://ufldl.stanford.edu/housenumbers/test_32x32.mat\n",
      "Повторное использование соединения с ufldl.stanford.edu:80.\n",
      "HTTP-запрос отправлен. Ожидание ответа... 416 Requested Range Not Satisfiable\n",
      "\n",
      "    Файл уже получен полностью; нет действий.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Intstall PyTorch and download data\n",
    "!pip3 install torch torchvision\n",
    "\n",
    "!wget -c http://ufldl.stanford.edu/housenumbers/train_32x32.mat http://ufldl.stanford.edu/housenumbers/test_32x32.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-afwWw-Q85vD"
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from torchvision import transforms\n",
    "from pytorch_helper import PyTorchHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NNU-OD9O9ltP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAt55B7I-YNA"
   },
   "source": [
    "# Загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YAvkoRx-9FsP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DjNAClx3-YNB"
   },
   "source": [
    "Разделяем данные на training и validation.\n",
    "\n",
    "На всякий случай для подробностей - https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YRnr8CPg7Hli"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0bcioK6JBDK"
   },
   "source": [
    "# Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_lenet():\n",
    "    return nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(4),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(4),    \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*2*2, 10),\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_O9qiYySvuj"
   },
   "source": [
    "# Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.43,0.44,0.47],\n",
    "                         std=[0.20,0.20,0.20])                   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, lets load the dataset\n",
    "data_train = dset.SVHN('./', transform=_transform)\n",
    "data_test = dset.SVHN('./', split='test', transform=_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hyperparameters(config, data_train, data_test):\n",
    "    device = torch.device(\"cuda:0\") # Let's make sure GPU is available!\n",
    "    # First, lets load the dataset\n",
    "    # The key hyperparameters we're going to tune are learning speed, annealing rate and regularization\n",
    "    # We also encourage you to try different optimizers as well\n",
    "    batch_size = 64\n",
    "    helper = PyTorchHelper(batch_size,  data_train)\n",
    "\n",
    "    train_indices, val_indices = helper.split(.2)\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "    val_loader = torch.utils.data.DataLoader(data_train, batch_size=batch_size,\n",
    "                                         sampler=val_sampler)\n",
    "    #===============================================\n",
    "\n",
    "    Hyperparams = namedtuple(\"Hyperparams\", ['learning_rate', 'anneal_epochs', 'reg'])\n",
    "    RunResult = namedtuple(\"RunResult\", ['model', 'train_history', 'val_history', 'final_val_accuracy'])\n",
    "\n",
    "    learning_rates = [1e-1]\n",
    "    anneal_coeff = 0.2\n",
    "    anneal_epochs = [5]\n",
    "    regs = [0.0001]\n",
    "    optimizers = [optim.SGD]\n",
    "\n",
    "    batch_size = 64\n",
    "    epoch_num = config['epoch_num']\n",
    "\n",
    "    # Record all the runs here\n",
    "    # Key should be Hyperparams and values should be RunResult\n",
    "    run_record = {} \n",
    "\n",
    "    # Use grid search or random search and record all runs in run_record dictionnary \n",
    "    # Important: perform search in logarithmic space!\n",
    "\n",
    "    # TODO: Your code here!\n",
    "\n",
    "    best_hyperparams = Hyperparams(None, None, None)\n",
    "    best_result = RunResult(None, None, None, None)\n",
    "\n",
    "    for lr, reg, anneal_epoch, optimizer in product(learning_rates, regs, anneal_epochs, optimizers):\n",
    "        lenet_model =base_lenet() # base_lenet()\n",
    "\n",
    "        lenet_model.type(torch.cuda.FloatTensor)\n",
    "        lenet_model.to(device)\n",
    "\n",
    "        loss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
    "\n",
    "        optimizer = optimizer(lenet_model.parameters(), lr=lr, weight_decay=reg)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=anneal_epoch, gamma=anneal_coeff)\n",
    "\n",
    "        params = Hyperparams(lr, anneal_epoch, reg)\n",
    "\n",
    "        print(f\"\\nCurrent hyperparams: {params}\")\n",
    "\n",
    "        loss_history, train_history, val_history = helper.train_model('best_lenet',lenet_model, train_loader, val_loader, loss, optimizer, epoch_num, scheduler)\n",
    "\n",
    "        result = RunResult(lenet_model, train_history, val_history, val_history[-1])\n",
    "        run_record[params] = result\n",
    "\n",
    "        if best_result.final_val_accuracy is None or best_result.final_val_accuracy < result.final_val_accuracy:\n",
    "            best_result = result\n",
    "            best_hyperparams = params\n",
    "\n",
    "        print(\"\\nCurrent best validation accuracy: %4.2f, best hyperparams: %s\" % (best_result.final_val_accuracy, best_hyperparams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'epoch_num': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find_hyperparameters(config,data_train, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-31 22:05:33,862\tINFO services.py:1263 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "2022-01-31 22:05:37,118\tWARNING function_runner.py:558 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 3.7/7.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/3.1 GiB heap, 0.0/1.55 GiB objects<br>Result logdir: /home/alex/ray_results/find_hyperparameters_2022-01-31_22-05-37<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>find_hyperparameters_3f178_00000</td><td>PENDING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3620)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=3620)\u001b[0m Current hyperparams: Hyperparams(learning_rate=0.1, anneal_epochs=5, reg=0.0001)\n",
      "\u001b[2m\u001b[36m(pid=3620)\u001b[0m Average loss: 1.431351, Train accuracy: 0.520288, Val accuracy: 0.767524\n",
      "Trial find_hyperparameters_3f178_00000 completed. Last result: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.2/7.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/3.1 GiB heap, 0.0/1.55 GiB objects<br>Result logdir: /home/alex/ray_results/find_hyperparameters_2022-01-31_22-05-37<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status    </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>find_hyperparameters_3f178_00000</td><td>TERMINATED</td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/7.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/3.1 GiB heap, 0.0/1.55 GiB objects<br>Result logdir: /home/alex/ray_results/find_hyperparameters_2022-01-31_22-05-37<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status    </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>find_hyperparameters_3f178_00000</td><td>TERMINATED</td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-31 22:06:20,960\tINFO tune.py:561 -- Total run time: 43.84 seconds (43.47 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3620)\u001b[0m Average loss: 0.711938, Train accuracy: 0.781712, Val accuracy: 0.796055\n",
      "\u001b[2m\u001b[36m(pid=3620)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=3620)\u001b[0m Current best validation accuracy: 0.80, best hyperparams: Hyperparams(learning_rate=0.1, anneal_epochs=5, reg=0.0001)\n"
     ]
    }
   ],
   "source": [
    " analysis = tune.run(\n",
    "        tune.with_parameters(find_hyperparameters,  data_train=data_train, data_test=data_test),\n",
    "        num_samples=1,\n",
    "        config=config,\n",
    "        resources_per_trial={\"cpu\": 8, \"gpu\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "Y6xExdw8JB1l",
    "outputId": "45e3e51e-25cd-426d-ce2b-e80e13c9e085"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_record' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-bf391b2656c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbest_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mhyperparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_result\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrun_record\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbest_val_accuracy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbest_val_accuracy\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mrun_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_val_accuracy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mbest_val_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_val_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'run_record' is not defined"
     ]
    }
   ],
   "source": [
    "best_val_accuracy = None\n",
    "best_hyperparams = None\n",
    "best_run = None\n",
    "\n",
    "for hyperparams, run_result in run_record.items():\n",
    "    if best_val_accuracy is None or best_val_accuracy < run_result.final_val_accuracy:\n",
    "        best_val_accuracy = run_result.final_val_accuracy\n",
    "        best_hyperparams = hyperparams\n",
    "        best_run = run_result\n",
    "        \n",
    "print(\"Best validation accuracy: %4.2f, best hyperparams: %s\" % (best_val_accuracy, best_hyperparams))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PyTorch_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
