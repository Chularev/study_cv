{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RKgBwXr-YM8"
   },
   "source": [
    "# Задание 3.2 - сверточные нейронные сети (CNNs) в PyTorch\n",
    "\n",
    "Это упражнение мы буде выполнять в Google Colab - https://colab.research.google.com/  \n",
    "Google Colab позволяет запускать код в notebook в облаке Google, где можно воспользоваться бесплатным GPU!  \n",
    "\n",
    "Авторы курса благодарят компанию Google и надеятся, что праздник не закончится.\n",
    "\n",
    "Туториал по настройке Google Colab:  \n",
    "https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d  \n",
    "(Keras инсталлировать не нужно, наш notebook сам установит PyTorch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FcXBeP1O7cnY",
    "outputId": "fd0c07fe-1ea3-42ed-80b5-80e4f7b9d161"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.10.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.11.1)\n",
      "Requirement already satisfied: typing-extensions in /home/alex/.local/lib/python3.8/site-packages (from torch) (4.0.1)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /home/alex/.local/lib/python3.8/site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.20.3)\n",
      "--2022-02-03 21:47:12--  http://ufldl.stanford.edu/housenumbers/train_32x32.mat\n",
      "Распознаётся ufldl.stanford.edu (ufldl.stanford.edu)... 171.64.68.10\n",
      "Подключение к ufldl.stanford.edu (ufldl.stanford.edu)|171.64.68.10|:80... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа... 416 Requested Range Not Satisfiable\n",
      "\n",
      "    Файл уже получен полностью; нет действий.\n",
      "\n",
      "--2022-02-03 21:47:12--  http://ufldl.stanford.edu/housenumbers/test_32x32.mat\n",
      "Повторное использование соединения с ufldl.stanford.edu:80.\n",
      "HTTP-запрос отправлен. Ожидание ответа... 416 Requested Range Not Satisfiable\n",
      "\n",
      "    Файл уже получен полностью; нет действий.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Intstall PyTorch and download data\n",
    "!pip3 install torch torchvision\n",
    "\n",
    "!wget -c http://ufldl.stanford.edu/housenumbers/train_32x32.mat http://ufldl.stanford.edu/housenumbers/test_32x32.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-afwWw-Q85vD"
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pytorch_helper import PyTorchHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NNU-OD9O9ltP"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAt55B7I-YNA"
   },
   "source": [
    "# Загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YAvkoRx-9FsP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DjNAClx3-YNB"
   },
   "source": [
    "Разделяем данные на training и validation.\n",
    "\n",
    "На всякий случай для подробностей - https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YRnr8CPg7Hli"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0bcioK6JBDK"
   },
   "source": [
    "# Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_lenet():\n",
    "    return nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(4),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(4),    \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*2*2, 10),\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_O9qiYySvuj"
   },
   "source": [
    "# Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.43,0.44,0.47],\n",
    "                         std=[0.20,0.20,0.20])                   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, lets load the dataset\n",
    "data_train = dset.SVHN('./', transform=_transform)\n",
    "data_test = dset.SVHN('./', split='test', transform=_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hyperparameters(config, data_train, data_test):\n",
    "    device = torch.device(\"cuda:0\") # Let's make sure GPU is available!\n",
    "    tensor_board = SummaryWriter(f'runs/exp1')\n",
    "    # First, lets load the dataset\n",
    "    # The key hyperparameters we're going to tune are learning speed, annealing rate and regularization\n",
    "    # We also encourage you to try different optimizers as well\n",
    "    batch_size = 64\n",
    "    helper = PyTorchHelper(batch_size,  data_train)\n",
    "\n",
    "    train_indices, val_indices = helper.split(.2)\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "    val_loader = torch.utils.data.DataLoader(data_train, batch_size=batch_size,\n",
    "                                         sampler=val_sampler)\n",
    "    #===============================================\n",
    "\n",
    "    Hyperparams = namedtuple(\"Hyperparams\", ['learning_rate', 'anneal_epochs', 'reg'])\n",
    "    RunResult = namedtuple(\"RunResult\", ['model', 'train_history', 'val_history', 'final_val_accuracy'])\n",
    "\n",
    "    learning_rates = [1e-1]\n",
    "    anneal_coeff = 0.2\n",
    "    anneal_epochs = [5]\n",
    "    regs = [0.0001]\n",
    "    optimizers = [optim.SGD]\n",
    "\n",
    "    batch_size = 64\n",
    "    epoch_num = config['epoch_num']\n",
    "\n",
    "    # Record all the runs here\n",
    "    # Key should be Hyperparams and values should be RunResult\n",
    "    run_record = {} \n",
    "\n",
    "    # Use grid search or random search and record all runs in run_record dictionnary \n",
    "    # Important: perform search in logarithmic space!\n",
    "\n",
    "    # TODO: Your code here!\n",
    "\n",
    "    best_hyperparams = Hyperparams(None, None, None)\n",
    "    best_result = RunResult(None, None, None, None)\n",
    "\n",
    "    for lr, reg, anneal_epoch, optimizer in product(learning_rates, regs, anneal_epochs, optimizers):\n",
    "        lenet_model =base_lenet() # base_lenet()\n",
    "\n",
    "        lenet_model.type(torch.cuda.FloatTensor)\n",
    "        lenet_model.to(device)\n",
    "\n",
    "        loss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
    "\n",
    "        optimizer = optimizer(lenet_model.parameters(), lr=lr, weight_decay=reg)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=anneal_epoch, gamma=anneal_coeff)\n",
    "\n",
    "        params = Hyperparams(lr, anneal_epoch, reg)\n",
    "\n",
    "        print(f\"\\nCurrent hyperparams: {params}\")\n",
    "\n",
    "        loss_history, train_history, val_history = helper.train_model('best_lenet',lenet_model, train_loader, val_loader, loss, optimizer, epoch_num, scheduler,tensor_board)\n",
    "\n",
    "        result = RunResult(lenet_model, train_history, val_history, val_history[-1])\n",
    "        run_record[params] = result\n",
    "\n",
    "        if best_result.final_val_accuracy is None or best_result.final_val_accuracy < result.final_val_accuracy:\n",
    "            best_result = result\n",
    "            best_hyperparams = params\n",
    "\n",
    "        print(\"\\nCurrent best validation accuracy: %4.2f, best hyperparams: %s\" % (best_result.final_val_accuracy, best_hyperparams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'epoch_num': tune.grid_search([2,1])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find_hyperparameters(config,data_train, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.8/7.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/2.05 GiB heap, 0.0/1.03 GiB objects<br>Result logdir: /mnt/heap/My folder/checpoint/experiment_name<br>Number of trials: 2/2 (2 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  epoch_num</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>find_hyperparameters_96453_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          2</td></tr>\n",
       "<tr><td>find_hyperparameters_96453_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.6/7.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/2.05 GiB heap, 0.0/1.03 GiB objects<br>Result logdir: /mnt/heap/My folder/checpoint/experiment_name<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  epoch_num</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>find_hyperparameters_96453_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">          2</td></tr>\n",
       "<tr><td>find_hyperparameters_96453_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10840)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=10840)\u001b[0m Current hyperparams: Hyperparams(learning_rate=0.1, anneal_epochs=5, reg=0.0001)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 7.4/7.7 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/2.05 GiB heap, 0.0/1.03 GiB objects<br>Result logdir: /mnt/heap/My folder/checpoint/experiment_name<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  epoch_num</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>find_hyperparameters_96453_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">          2</td></tr>\n",
       "<tr><td>find_hyperparameters_96453_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10840)\u001b[0m Average loss: 1.406943, Train accuracy: 0.531106, Val accuracy: 0.770937\n",
      "\u001b[2m\u001b[36m(pid=10840)\u001b[0m Average loss: 0.706810, Train accuracy: 0.784476, Val accuracy: 0.801720\n",
      "Trial find_hyperparameters_96453_00000 completed. Last result: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 7.1/7.7 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/2.05 GiB heap, 0.0/1.03 GiB objects<br>Result logdir: /mnt/heap/My folder/checpoint/experiment_name<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  epoch_num</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>find_hyperparameters_96453_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">          2</td></tr>\n",
       "<tr><td>find_hyperparameters_96453_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-03 21:58:09,369\tERROR checkpoint_manager.py:144 -- Result dict has no key: training_iteration. checkpoint_score_attr must be set to a key in the result dict.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10840)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=10840)\u001b[0m Current best validation accuracy: 0.80, best hyperparams: Hyperparams(learning_rate=0.1, anneal_epochs=5, reg=0.0001)\n",
      "\u001b[2m\u001b[36m(pid=10841)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=10841)\u001b[0m Current hyperparams: Hyperparams(learning_rate=0.1, anneal_epochs=5, reg=0.0001)\n",
      "\u001b[2m\u001b[36m(pid=10841)\u001b[0m Average loss: 1.419146, Train accuracy: 0.526124, Val accuracy: 0.758242\n",
      "Trial find_hyperparameters_96453_00001 completed. Last result: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 7.0/7.7 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/2.05 GiB heap, 0.0/1.03 GiB objects<br>Result logdir: /mnt/heap/My folder/checpoint/experiment_name<br>Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  epoch_num</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>find_hyperparameters_96453_00001</td><td>RUNNING   </td><td>     </td><td style=\"text-align: right;\">          1</td></tr>\n",
       "<tr><td>find_hyperparameters_96453_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-03 21:58:41,183\tERROR checkpoint_manager.py:144 -- Result dict has no key: training_iteration. checkpoint_score_attr must be set to a key in the result dict.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10841)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=10841)\u001b[0m Current best validation accuracy: 0.76, best hyperparams: Hyperparams(learning_rate=0.1, anneal_epochs=5, reg=0.0001)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 7.0/7.7 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/2.05 GiB heap, 0.0/1.03 GiB objects<br>Result logdir: /mnt/heap/My folder/checpoint/experiment_name<br>Number of trials: 2/2 (2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  epoch_num</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>find_hyperparameters_96453_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          2</td></tr>\n",
       "<tr><td>find_hyperparameters_96453_00001</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-03 21:58:41,315\tINFO tune.py:561 -- Total run time: 80.90 seconds (80.72 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    " analysis = tune.run(\n",
    "    tune.with_parameters(find_hyperparameters,  data_train=data_train, data_test=data_test),\n",
    "        \n",
    "    name=\"experiment_name\",\n",
    "    local_dir=\"/mnt/heap/My folder/checpoint\",\n",
    "    num_samples=1,\n",
    "    config=config,\n",
    "    resources_per_trial={\"cpu\": 8, \"gpu\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "Y6xExdw8JB1l",
    "outputId": "45e3e51e-25cd-426d-ce2b-e80e13c9e085"
   },
   "outputs": [],
   "source": [
    "best_val_accuracy = None\n",
    "best_hyperparams = None\n",
    "best_run = None\n",
    "\n",
    "for hyperparams, run_result in run_record.items():\n",
    "    if best_val_accuracy is None or best_val_accuracy < run_result.final_val_accuracy:\n",
    "        best_val_accuracy = run_result.final_val_accuracy\n",
    "        best_hyperparams = hyperparams\n",
    "        best_run = run_result\n",
    "        \n",
    "print(\"Best validation accuracy: %4.2f, best hyperparams: %s\" % (best_val_accuracy, best_hyperparams))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PyTorch_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
